
= Data Access With _nccopy_

== Environment
You will need to have installed the netcdf-c library in order to complete
this tutorial. Because the tutorial examples are primarily DAP4, the netcdf-c
library version 4.9.0 or newer is recommended. This tutorial was developed using
_netcdf library version 4.9.0 of Feb 13 2023 10:14:14 $_

With netcdf-c library installed on your system you should be able to run
ncdump and nccopy from any terminal window.

This tutorial assumes that the reader has a good grasp of bash shell
programming.

The NASA examples in this document will require that the user configure
their client applications to authenticate with the NASA EDL OAuth2 service.
Since the authentication setup is complex, yet similar for many clients. We
have covered it in a separate document.

**TODO: _LINK TO CLIENT AUTHENTICATION DOCUMENTS HERE_**

If you have not done that yet, go do that now!


== Overview
The `nccopy` application is a command line tool that can be used to:

* Build a custom netcdf file from an existing netcdf file.
* Build a custom netcdf file from a remote DAP2 or DAP4 data service.
* Fine tune the compression and chunking parameters in the resulting file.

When `nccopy` accesses remote data via the DAP2 and DAP4 protocol the server
is able to stream the response back. Data transmission begins almost immediately.
In contrast, when a user asks the server to return a response encoded as a
netcdf-4 file, the server cannot stream the response because of the way the
netcdf-4 is structured: bytes at the beginning of the file are modified when the
file is closed after creation. This means that there can be a lengthy delay
before the server can begin transmitting the netcdf-4 result. When `nccopy` is
used the delay is eliminated and the result is also a netcdf04 file on local
disk. Oh Snap.

In this tutorial we will work with the retrieval of remote data.

=== nccopy

The `nccopy` application is a linux command line program that is typically
installed with the netcdf-c libraries (and often can be acquired from a package
manager such as _brew/yum/dnf/apt-get_. It allows the user to rewrite netcdf
files on the local disk, and using the DAP2 and DAP4 protocols it can also
rewrite remote datasets with a DAP access url and store the results on local
disk. It provides options for output file format, customizing the internal
data compression, chunk sizes, and selecting data and/or definitions so that
not everything is brought from the source dataset.

In this tutorial we will focus on the remote data access aspects of nccopy. We
leave the nuances of the compression and chunking controls to you, the capable
user.

Here is nccopy's usage output:
--------------------------------------------------------------
nccopy: nccopy [-k kind] [-[3|4|6|7]] [-d n] [-s] [-c chunkspec] [-u] [-w] [-[v|V] varlist] [-[g|G] grplist] [-m n] [-h n] [-e n] [-r] [-F filterspec] [-Ln] [-Mn] infile outfile
[-k kind] specify kind of netCDF format for output file, default same as input
kind strings: 'classic', '64-bit offset', 'cdf5',
'netCDF-4', 'netCDF-4 classic model'
[-3]      netCDF classic output (same as -k 'classic')
[-6]      64-bit-offset output (same as -k '64-bit offset')
[-4]      netCDF-4 output (same as -k 'netCDF-4')
[-7]      netCDF-4-classic output (same as -k 'netCDF-4 classic model')
[-5]      CDF5 output (same as -k 'cdf5)
[-d n]    set output deflation compression level, default same as input (0=none 9=max)
[-s]      add shuffle option to deflation compression
[-c chunkspec] specify chunking for variable and dimensions, e.g. "var:N1,N2,..." or "dim1/N1,dim2/N2,..."
[-u]      convert unlimited dimensions to fixed-size dimensions in output copy
[-w]      write whole output file from diskless netCDF on close
[-v var1,...] include data for only listed variables, but definitions for all variables
[-V var1,...] include definitions and data for only listed variables
[-g grp1,...] include data for only variables in listed groups, but all definitions
[-G grp1,...] include definitions and data only for variables in listed groups
[-m n]    set size in bytes of copy buffer, default is 5000000 bytes
[-h n]    set size in bytes of chunk_cache for chunked variables
[-e n]    set number of elements that chunk_cache can hold
[-r]      read whole input file into diskless file on open (classic or 64-bit offset or cdf5 formats only)
[-F filterspec] specify a compression algorithm to apply to an output variable (may be repeated).
[-Ln]     set log level to n (>= 0); ignored if logging isn't enabled.
[-Mn]     set minimum chunk size to n bytes (n >= 0)
infile    name of netCDF input file
outfile   name for netCDF output file

netCDF library version 4.9.0 of Oct  2 2022 23:17:14 $
--------------------------------------------------------------

=== The Data

In these examples will use the following remote datasets:

https://opendap.uat.earthdata.nasa.gov/collections/C1225808238-GES_DISC/granules/GPM_3IMERGHH.06%3A3B-HHR.MS.MRG.3IMERG.20200101-S000000-E002959.0000.V06B.HDF5[A Granule]
- from NASA's GPM IMERG Final Precipitation Level 3 (L3) collection served
by Hyrax in NGAP

This is a DAP4 dataset: It contains a Group named Grid which contains all the
other components of the dataset. Because of this we need to tell the `nccopy`
software to use the DAP4 protocol to access the data. We do this by changing
the `https://` at the begining of the dataset URL to `dap4://`

This dataset Url:
----
https://opendap.uat.earthdata.nasa.gov/collections/C1225808238-GES_DISC/granules/GPM_3IMERGHH.06%3A3B-HHR.MS.MRG.3IMERG.20200101-S000000-E002959.0000.V06B.HDF5
----
Becomes this DAP4 URL:
----
dap4://opendap.uat.earthdata.nasa.gov/collections/C1225808238-GES_DISC/granules/GPM_3IMERGHH.06%3A3B-HHR.MS.MRG.3IMERG.20200101-S000000-E002959.0000.V06B.HDF5
----

== Examples
_Since `nccopy` is a linux command line tool, I have written the examples in the
bash shell._

=== Full Granule Rewrite
In which we retrieve all the data from a remote DAP4 serviced granule with
a Group hierarchy.
----
#!/bin/bash
#
# The dataset_url is the DAP service endpoint. In the case of this server the
# DAP2 and DAP4 endpoints are the same.

d4_url="dap4://opendap.uat.earthdata.nasa.gov/collections/C1225808238-GES_DISC/granules/GPM_3IMERGHH.06%3A3B-HHR.MS.MRG.3IMERG.20200101-S000000-E002959.0000.V06B.HDF5"

# We use the "-4" option to tell nccopy to make a netcdf-4 file. This is
# important because netcdf-3 does not support Groups
nccopy -4 ${d4_url} foo.nc4

# fini
----

=== Inventory Sub-setting

There are two ways to perform inventory sub-setting with `nccopy`. The `nccopy` way,
and the DAP way. The `nccopy` application has options that allow you to select
one or more variables and/or Groups (and their children) so that the resulting
local netcdf file created by nccopy contains only the desired data.

==== The nccopy way
Returning to our example dataset we'll form an `nccopy` command in which we
will utilize the `-V` option to request the
domain variables for _time_, _latitude_, and _longitude_, and the range variables
_precipitationCal_ and _IRprecipitation_. Because each of these variables is a
member of the Group Grid, we must include the Group's name in the Fully
Qualified Name (FQN)  of each item requested.
----
#!/bin/bash
#
# The DAP4 protocol endpoint URL for granule
d4_url="dap4://opendap.uat.earthdata.nasa.gov/collections/C1225808238-GES_DISC/granules/GPM_3IMERGHH.06%3A3B-HHR.MS.MRG.3IMERG.20200101-S000000-E002959.0000.V06B.HDF5"

# We use the "-4" option to tell nccopy to make a netcdf-4 file. This is
# important because netcdf-3 does not support Groups
# We use the "-V" option to specify what to get.
nccopy -4 -V /Grid/time,/Grid/lat,/Grid/lon,/Grid/precipitationCal,/Grid/IRprecipitation ${d4_url} foo.nc4

# fini
----
==== The DAP4 Way
The DAP4 way means using a DAP4 constraint expression (d4_ce) to tell the
server which things to get. The difference is subtle, and this example may seem
redundant, but this technique can be used in other contexts.
----
#!/bin/bash
#
# The DAP4 protocol endpoint URL for the test granule
d4_url="dap4://opendap.uat.earthdata.nasa.gov/collections/C1225808238-GES_DISC/granules/GPM_3IMERGHH.06%3A3B-HHR.MS.MRG.3IMERG.20200101-S000000-E002959.0000.V06B.HDF5"

# The DAP4 constraint expression to use with the request
d4_ce="dap4.ce=/Grid/time;/Grid/lat;/Grid/lon;/Grid/precipitationCal;/Grid/IRprecipitation"

nccopy -4 "${d4_url}?{d4_ce}" foo.nc4

# fini
----
